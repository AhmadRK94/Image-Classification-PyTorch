{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1370c9ef",
   "metadata": {},
   "source": [
    "# Pure Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fcbecf",
   "metadata": {},
   "source": [
    "for every deep learning task in PyTorch, we need:\n",
    "   * **Data**\n",
    "   * **device** which set our model to use GPU if it is available.\n",
    "   * **Model**\n",
    "   * **Loss function**\n",
    "   * **Optimizer**\n",
    "   * **Train** and **Validation/Test** loop. also, our train loop will have the following steps:\n",
    "      * forward propagation through our network\n",
    "      * calculate our loss\n",
    "      * put our previous gradients to zero\n",
    "      * calculate new gradients\n",
    "      * update our parameters<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738f3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51de80",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378921c",
   "metadata": {},
   "source": [
    "here we are going to use the MNIST digits dataset which is provided in the PyTorch package so we just need to download it. at the end of the notebook, I'll show how to use your custom datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6411de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(os.getcwd(), train=True,transform=transforms.ToTensor(),download=True)\n",
    "val_dataset = datasets.MNIST(os.getcwd(), train=False,transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3369b8",
   "metadata": {},
   "source": [
    "some of our hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922db164",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 1*28*28\n",
    "N_HIDDEN = 100\n",
    "N_OUTPUT = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9d4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=8)\n",
    "val_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ad932",
   "metadata": {},
   "source": [
    "## Set our device to GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b64392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7ea35",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b0fb3",
   "metadata": {},
   "source": [
    "first, we are going to use a fully connected neural network which is not the best choice for image classification. later we will use a convolutional neural network and see how it will effect our accuracy.<br>\n",
    "**NOTE:** all the models and choice of hyperparameters in this notebook are very simple and it is just for learning purposes. we just need to learn how to use various pieces for our model, and that is our goal here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52dbcc",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8b451",
   "metadata": {},
   "source": [
    "there are various ways to create models in PyTorch but the best way is to use class. our model class has 2 main parts:\n",
    "   * The `__init__` function contains everything we need for creating our model.\n",
    "   * The `forward` function which is our forward pass in our model.<br>\n",
    "\n",
    "**NOTE:** in our class we have to Inheritance `nn.Module`. that is how our model understands the forward method and other methods we are going to use later.<br>\n",
    "**NOTE:** we can define various functions in our class and use them to create our model (particularly for defining our forward function). keep it mind that some of the names like `forward` are reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b874b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_input,n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.output = nn.Linear(n_hidden,n_output)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456cc96",
   "metadata": {},
   "source": [
    "now we instantiate our model with proper inputs that we define in the `__init__` function.<br>\n",
    "**NOTE:** as you can see we use `.to(device)` to set our device for our **model**. later we have to do this for our **X** and **y** too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02a32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCNN(N_INPUT,N_HIDDEN,N_OUTPUT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50531fd",
   "metadata": {},
   "source": [
    "### Defining Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d7f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "# optimizer = optim.SGD(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ba45f",
   "metadata": {},
   "source": [
    "### Train and Validation/Test Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0df711",
   "metadata": {},
   "source": [
    "in PyTorch, we have to define our train and validation/test loop manually. as we said before it contains 5 steps. also in the validation loop, we have to set our model in `eval()` mode and perform forward propagation in `inference_mode()`.these two steps are important specially when we have **dropout** and **batch normalization** in our model.<br>\n",
    "**NOTE:** one of the advantages of using other PyTorch packages like PyTorch_Lightning and fastai is that it automates these loops for us, so we don't have to write them ourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d6cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train loss: 0.30 | validarion loss: 0.19\n",
      "Epoch 2 | train loss: 0.14 | validarion loss: 0.16\n",
      "Epoch 3 | train loss: 0.11 | validarion loss: 0.13\n",
      "Epoch 4 | train loss: 0.09 | validarion loss: 0.10\n",
      "Epoch 5 | train loss: 0.08 | validarion loss: 0.12\n",
      "CPU times: total: 34 s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    #train loop\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_data in train_loader:\n",
    "        X_train,y_train = batch_data\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "        \n",
    "        train_logits = model(X_train) # 1- forward propagation\n",
    "        cost = loss(train_logits,y_train) # 2- calculating loss\n",
    "        \n",
    "        optimizer.zero_grad() # 3- zero previous gradients\n",
    "        cost.backward() # 4- calculate new gradients\n",
    "        \n",
    "        optimizer.step() # 5- update our parameters\n",
    "        \n",
    "        train_losses.append(cost.item())\n",
    "    \n",
    "    #validation/test loop\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    for batch_data in val_loader:\n",
    "        X_val,y_val = batch_data\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        X_val = X_val.reshape(X_val.shape[0],-1)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            val_logits = model(X_val)\n",
    "        val_cost = loss(val_logits,y_val)\n",
    "        val_losses.append(val_cost.item())\n",
    "    print(f'Epoch {epoch + 1} | train loss: {torch.tensor(train_losses).mean():.2f} | validarion loss: {torch.tensor(val_losses).mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd42ba",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f38c8d",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2df75369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes=10,num_channel=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=num_channel,kernel_size=5,padding=2,stride=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channel)\n",
    "        self.conv2 = nn.Conv2d(in_channels=num_channel,out_channels=num_channel*2,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channel*2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(2*num_channel*7*7,num_channel*7*7)\n",
    "        self.bn3 = nn.BatchNorm1d(num_channel*7*7)\n",
    "        self.fc2 = nn.Linear(num_channel*7*7,num_classes)\n",
    "        self.dp = nn.Dropout(0.25)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0547f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ef312",
   "metadata": {},
   "source": [
    "### Defining Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d31aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c0d0e",
   "metadata": {},
   "source": [
    "### Training and Validation/Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d15968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train loss: 0.14 | validarion loss: 0.05\n",
      "Epoch 2 | train loss: 0.07 | validarion loss: 0.04\n",
      "Epoch 3 | train loss: 0.06 | validarion loss: 0.03\n",
      "Epoch 4 | train loss: 0.04 | validarion loss: 0.02\n",
      "Epoch 5 | train loss: 0.04 | validarion loss: 0.03\n",
      "CPU times: total: 8min 15s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    #train loop\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_data in train_loader:\n",
    "        X_train,y_train = batch_data\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        \n",
    "        train_logits = model(X_train)\n",
    "        cost = loss(train_logits,y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(cost.item())\n",
    "    \n",
    "    #validation/test loop\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    for batch_data in val_loader:\n",
    "        X_val,y_val = batch_data\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            val_logits = model(X_val)\n",
    "        val_cost = loss(val_logits,y_val)\n",
    "        val_losses.append(val_cost.item())\n",
    "    print(f'Epoch {epoch + 1} | train loss: {torch.tensor(train_losses).mean():.2f} | validarion loss: {torch.tensor(val_losses).mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23835f38",
   "metadata": {},
   "source": [
    "# Pytorch + Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035aa214",
   "metadata": {},
   "source": [
    "PyTorch_Lightening is one of the packages that build on top of PyTorch and it adds so much functionality to it. here we are going to just use the basic one which is automating our train and validation loop. but it has so many amazing features. so make sure you check their documentation before using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2eebd",
   "metadata": {},
   "source": [
    "in Lightening we define everything in our model class:\n",
    "   1) we use `LightningModule` instead of `nn.Module` which has all the methods in `nn.Module` plus some additional methods, which we will use to create our loops.\n",
    "   2) beside `__init__` and `forward` methods we have to define:\n",
    "       * `configure_optimizers` which we use to define our optimizers.\n",
    "       * `training_step` which we use to define our training loop.\n",
    "       * `validation_step` which we use to define our validation_loop.<br>\n",
    "       \n",
    "\n",
    "   3) we don't need to set the device here, and lightning will automatically do it for us.\n",
    "   4) it will perform 4 of 5 steps in the train loop for us (not forward propagation).\n",
    "   5) it will automatically set all the necessary modes in our validation loop.<br>\n",
    "\n",
    "**NOTE:** besides these methods, lightning has more methods that can help us for creating models with more functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5445340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea76d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFCNN(pl.LightningModule):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_input,n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.output = nn.Linear(n_hidden,n_output)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(),lr=LEARNING_RATE)\n",
    "        return optimizer\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        X_train,y_train = batch\n",
    "        X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "        logits = self(X_train)\n",
    "        train_loss = self.loss(logits,y_train)\n",
    "        self.log(\"train_loss\", train_loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return train_loss\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        X_val,y_val = batch\n",
    "        X_val = X_val.reshape(X_val.shape[0],-1)\n",
    "        logits = self(X_val)\n",
    "        val_loss = self.loss(logits,y_val)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca37d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LFCNN(N_INPUT,N_HIDDEN,N_OUTPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86487c",
   "metadata": {},
   "source": [
    "in Lightning to train our model, we have to create `.Trainer` which makes everything so much easier. we can set so many things in our trainer so make sure to check their documentation. here we just set our number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "322bd577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf1006",
   "metadata": {},
   "source": [
    "now we just simply use `.fit` method to train our model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | fc1    | Linear           | 78.5 K\n",
      "1 | fc2    | Linear           | 10.1 K\n",
      "2 | output | Linear           | 1.0 K \n",
      "3 | bn1    | BatchNorm1d      | 200   \n",
      "4 | dp     | Dropout          | 0     \n",
      "5 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "89.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.8 K    Total params\n",
      "0.359     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb8e9b166974c27927654b1c09a17fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39.5 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.fit(model,train_dataloaders=train_loader,val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0af8b",
   "metadata": {},
   "source": [
    "# Pytorch + Fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e13f1",
   "metadata": {},
   "source": [
    "fastai is another package that builds on top of PyTorch and again it has so many features in it. here again, we just use some of their functionalities to automate our training and validation loop. so make sure you read their documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc88752",
   "metadata": {},
   "source": [
    "here our model is the same model that we define for our PyTorch with very minor changes (which we can do it for the PyTorch model too). instead of flattening our input in our training loop, we flatten our data in our forward method.<br>\n",
    "then we put our train_loader and val_loader in the `DataLoaders` class from fastai. then we define our `Learner` with proper data, model, loss function, optimization, and metrics. after that, we simply perform the `.fit` method on our learner with the proper number of epochs and other desired settings. here we use the `.fit_one_cycle` method which will do some useful things for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "656f8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "454579a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoaders(train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aedad3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_input,n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.output = nn.Linear(n_hidden,n_output)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60a5acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCNN(N_INPUT,N_HIDDEN,N_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00ac29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data,model , loss_func=nn.CrossEntropyLoss(), opt_func=Adam, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fbc3497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.224382</td>\n",
       "      <td>0.303103</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.145839</td>\n",
       "      <td>0.222675</td>\n",
       "      <td>0.932600</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118278</td>\n",
       "      <td>0.145812</td>\n",
       "      <td>0.958700</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080139</td>\n",
       "      <td>0.157013</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075030</td>\n",
       "      <td>0.159532</td>\n",
       "      <td>0.948500</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb94920",
   "metadata": {},
   "source": [
    "# Using Custom Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3779f3",
   "metadata": {},
   "source": [
    "probably there are various ways to load our custom datasets for training our model but I think this way is much easier at least for me.<br>\n",
    "here we need to store our train images and test images in 2 different folders. then make sure your image with the same label has something in common for example here we have images of cats and dogs. so each picture of cats has 'cat' in it. it helps us to label our images.<br>\n",
    "what we going to do is that we create two pandas DataFrame and put image names and corresponding labels in it both for testing and training images. then we use these DataFrames to read images and send them to our model.<br>\n",
    "for reading our images we create our dataset class which:<br>\n",
    "   1) have to Inheritance from `Dataset`.\n",
    "   2) has `__len__` method which return number of samples.\n",
    "   3) has the `__get__` method which will return our images and labels to our model.<br>\n",
    "\n",
    "after we define our dataset class we just instantiate our class with proper inputs and then put them in `Dataloader`, and the rest is like what we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82286f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "386f4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "train_path = current_path+\"\\\\all_train_image\"\n",
    "test_path = current_path+\"\\\\all_test_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8092a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = {'names':[],\n",
    "      'labels':[]\n",
    "}\n",
    "df_test = {'names':[],\n",
    "      'labels':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90799757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(train_path):\n",
    "    df_train['names'].append(file)\n",
    "    if 'cat' in file.lower():\n",
    "        df_train['labels'].append(0)\n",
    "    elif 'dog' in file.lower():\n",
    "        df_train['labels'].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b945f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(test_path):\n",
    "    df_test['names'].append(file)\n",
    "    if 'cat' in file.lower():\n",
    "        df_test['labels'].append(0)\n",
    "    elif 'dog' in file.lower():\n",
    "        df_test['labels'].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc451a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.DataFrame(df_train)\n",
    "test_csv = pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a1eaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatsAndDogsDataset(Dataset):\n",
    "    def __init__(self,train_csv,root_dir,transform=None):\n",
    "        self.annotation = train_csv\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotation)\n",
    "    def __getitem__(self,index):\n",
    "        img_path = os.path.join(self.root_dir,self.annotation.iloc[index,0])\n",
    "        image = Image.open(img_path)\n",
    "        y_label = torch.tensor(int(self.annotation.iloc[index,1]))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5226fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CatsAndDogsDataset(train_csv,train_path,transform=None)\n",
    "test_data = CatsAndDogsDataset(test_csv,test_path,transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3529ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee7119",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded6175",
   "metadata": {},
   "source": [
    "here we are going to use `ResNet50` to train our cats and dogs classifier (on our custom dataset). so we have to:\n",
    "   1) download the resnet50 model with pre-trained weights.\n",
    "   2) freeze all the parameters (or maybe some of them) so that they don't change during training.\n",
    "   3) change the output layer of the model (or some of the layers) according to our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be6415e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50,ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75b664b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ResNet50_Weights.IMAGENET1K_V2\n",
    "model = resnet50(weights=parameters)\n",
    "preprocess = parameters.transforms() # this is our proper preprocessing needed for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dcb6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c68bad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=1024, out_features=2, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0240892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CatsAndDogsDataset(train_csv,train_path,transform=preprocess)\n",
    "test_data = CatsAndDogsDataset(test_csv,test_path,transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95911fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbba6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoaders(train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "055885d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data,model , loss_func=nn.CrossEntropyLoss(), opt_func=Adam, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00d8f6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064040</td>\n",
       "      <td>0.041858</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>12:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd7ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
